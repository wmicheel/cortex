//
//  SpeechRecognitionService.swift
//  Cortex
//
//  Created by Claude Code
//

import Foundation
import Speech
import AVFoundation
import CoreAudio

/// Service for speech recognition and audio recording
@MainActor
final class SpeechRecognitionService {
    // MARK: - Properties

    private let speechRecognizer: SFSpeechRecognizer
    private let audioEngine = AVAudioEngine()
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private var lastTranscription: String = ""

    // MARK: - Initialization

    init(locale: Locale = Locale(identifier: "de-DE")) {
        print("üéôÔ∏è SpeechRecognitionService: init() START")
        print("üéôÔ∏è SpeechRecognitionService: Requested locale: \(locale.identifier)")

        // Try to create recognizer with requested locale (default: de-DE)
        if let recognizer = SFSpeechRecognizer(locale: locale) {
            print("üéôÔ∏è SpeechRecognitionService: ‚úÖ Created recognizer with locale: \(locale.identifier)")
            self.speechRecognizer = recognizer
        } else if let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "de-DE")) {
            print("üéôÔ∏è SpeechRecognitionService: ‚úÖ Fallback: Created recognizer with de-DE locale")
            self.speechRecognizer = recognizer
        } else if let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US")) {
            print("üéôÔ∏è SpeechRecognitionService: ‚ö†Ô∏è Fallback: Created recognizer with en-US locale")
            self.speechRecognizer = recognizer
        } else {
            print("üéôÔ∏è SpeechRecognitionService: ‚ùå ERROR - Could not create recognizer with any locale")
            fatalError("SFSpeechRecognizer could not be initialized")
        }

        print("üéôÔ∏è SpeechRecognitionService: init() COMPLETE - Using locale: \(speechRecognizer.locale.identifier)")
    }

    // MARK: - Authorization

    /// Request speech recognition authorization
    func requestAuthorization() async -> SFSpeechRecognizerAuthorizationStatus {
        await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status)
            }
        }
    }

    /// Check if authorized for speech recognition
    var isAuthorized: Bool {
        SFSpeechRecognizer.authorizationStatus() == .authorized
    }

    /// Check if speech recognition is available
    var isAvailable: Bool {
        speechRecognizer.isAvailable
    }

    // MARK: - Audio Device Management

    /// Get list of available audio input devices
    func getAvailableInputDevices() -> [AudioDevice] {
        var devices: [AudioDevice] = []

        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDevices,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )

        var dataSize: UInt32 = 0
        let status = AudioObjectGetPropertyDataSize(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            &dataSize
        )

        guard status == kAudioHardwareNoError else { return devices }

        let deviceCount = Int(dataSize) / MemoryLayout<AudioDeviceID>.size
        var deviceIDs = [AudioDeviceID](repeating: 0, count: deviceCount)

        AudioObjectGetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            &dataSize,
            &deviceIDs
        )

        for deviceID in deviceIDs {
            // Check if device has input streams
            var inputPropertyAddress = AudioObjectPropertyAddress(
                mSelector: kAudioDevicePropertyStreams,
                mScope: kAudioDevicePropertyScopeInput,
                mElement: kAudioObjectPropertyElementMain
            )

            var inputDataSize: UInt32 = 0
            AudioObjectGetPropertyDataSize(
                deviceID,
                &inputPropertyAddress,
                0,
                nil,
                &inputDataSize
            )

            // Only include devices with input streams
            guard inputDataSize > 0 else { continue }

            // Get device name
            var namePropertyAddress = AudioObjectPropertyAddress(
                mSelector: kAudioObjectPropertyName,
                mScope: kAudioObjectPropertyScopeGlobal,
                mElement: kAudioObjectPropertyElementMain
            )

            var deviceName: CFString = "" as CFString
            var nameSize = UInt32(MemoryLayout<CFString>.size)

            AudioObjectGetPropertyData(
                deviceID,
                &namePropertyAddress,
                0,
                nil,
                &nameSize,
                &deviceName
            )

            devices.append(AudioDevice(
                id: String(deviceID),
                name: deviceName as String,
                deviceID: deviceID
            ))
        }

        return devices
    }

    /// Set the audio input device to use for recording
    func setInputDevice(_ device: AudioDevice) {
        print("üéôÔ∏è SpeechRecognitionService: Setting input device to: \(device.name)")

        // Set the device as the input device for the audio engine
        var propertyAddress = AudioObjectPropertyAddress(
            mSelector: kAudioHardwarePropertyDefaultInputDevice,
            mScope: kAudioObjectPropertyScopeGlobal,
            mElement: kAudioObjectPropertyElementMain
        )

        var deviceID = device.deviceID
        let size = UInt32(MemoryLayout<AudioDeviceID>.size)

        AudioObjectSetPropertyData(
            AudioObjectID(kAudioObjectSystemObject),
            &propertyAddress,
            0,
            nil,
            size,
            &deviceID
        )
    }

    // MARK: - Recording

    /// Start recording and live transcription
    /// - Parameter onPartialResult: Callback for partial transcription updates
    /// - Returns: Recording session ID
    func startRecording(onPartialResult: @escaping (String) -> Void) async throws {
        print("üéôÔ∏è SpeechRecognitionService: startRecording() called")

        // Cancel any ongoing recognition
        print("üéôÔ∏è SpeechRecognitionService: Stopping any existing recording")
        _ = stopRecording()

        // Check authorization
        print("üéôÔ∏è SpeechRecognitionService: Checking authorization - isAuthorized: \(isAuthorized)")
        guard isAuthorized else {
            print("üéôÔ∏è SpeechRecognitionService: NOT AUTHORIZED - throwing error")
            throw SpeechRecognitionError.notAuthorized
        }

        print("üéôÔ∏è SpeechRecognitionService: Checking availability - isAvailable: \(isAvailable)")
        guard isAvailable else {
            print("üéôÔ∏è SpeechRecognitionService: NOT AVAILABLE - throwing error")
            throw SpeechRecognitionError.notAvailable
        }

        print("üéôÔ∏è SpeechRecognitionService: Authorization and availability checks passed")

        // Note: AVAudioSession is iOS-only. macOS handles audio automatically.

        print("üéôÔ∏è SpeechRecognitionService: Creating recognition request")
        // Create recognition request
        let request = SFSpeechAudioBufferRecognitionRequest()
        recognitionRequest = request
        request.shouldReportPartialResults = true
        print("üéôÔ∏è SpeechRecognitionService: Recognition request created")

        // Configure audio engine
        print("üéôÔ∏è SpeechRecognitionService: Configuring audio engine")
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        print("üéôÔ∏è SpeechRecognitionService: Recording format: \(recordingFormat)")

        print("üéôÔ∏è SpeechRecognitionService: Installing audio tap")
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            request.append(buffer)
        }

        print("üéôÔ∏è SpeechRecognitionService: Preparing audio engine")
        audioEngine.prepare()

        print("üéôÔ∏è SpeechRecognitionService: Starting audio engine")
        try audioEngine.start()
        print("üéôÔ∏è SpeechRecognitionService: Audio engine started successfully")

        // Start recognition task
        recognitionTask = speechRecognizer.recognitionTask(with: request) { [weak self] result, error in
            guard let self = self else { return }

            if let result = result {
                let transcription = result.bestTranscription.formattedString

                // Store last transcription
                Task { @MainActor in
                    self.lastTranscription = transcription
                    onPartialResult(transcription)
                }
            }

            if error != nil || result?.isFinal == true {
                // Recognition finished
            }
        }
    }

    /// Stop recording and return final transcription
    /// - Returns: Final transcribed text
    func stopRecording() -> String {
        // Finish recognition request first
        recognitionRequest?.endAudio()

        // Get final transcription
        let finalText = lastTranscription

        // Cancel task
        if let task = recognitionTask {
            task.cancel()
        }

        // Stop audio engine
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }

        // Cleanup
        recognitionRequest = nil
        recognitionTask = nil
        lastTranscription = ""

        return finalText
    }
}

// MARK: - Audio Device Model

/// Represents an audio input device
struct AudioDevice: Identifiable, Hashable {
    let id: String
    let name: String
    let deviceID: AudioDeviceID

    func hash(into hasher: inout Hasher) {
        hasher.combine(id)
    }

    static func == (lhs: AudioDevice, rhs: AudioDevice) -> Bool {
        lhs.id == rhs.id
    }
}

// MARK: - Errors

enum SpeechRecognitionError: LocalizedError {
    case notAuthorized
    case notAvailable
    case recordingFailed(Error)

    var errorDescription: String? {
        switch self {
        case .notAuthorized:
            return "Spracherkennung nicht autorisiert. Bitte erlauben Sie den Zugriff in den Systemeinstellungen."
        case .notAvailable:
            return "Spracherkennung ist momentan nicht verf√ºgbar. Bitte √ºberpr√ºfen Sie Ihre Internetverbindung."
        case .recordingFailed(let error):
            return "Aufnahme fehlgeschlagen: \(error.localizedDescription)"
        }
    }

    var recoverySuggestion: String? {
        switch self {
        case .notAuthorized:
            return "√ñffnen Sie Systemeinstellungen ‚Üí Datenschutz & Sicherheit ‚Üí Mikrofon/Spracherkennung"
        case .notAvailable:
            return "Versuchen Sie es sp√§ter erneut oder √ºberpr√ºfen Sie Ihre Netzwerkverbindung."
        case .recordingFailed:
            return "Stellen Sie sicher, dass Ihr Mikrofon richtig angeschlossen ist."
        }
    }
}
